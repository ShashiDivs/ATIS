{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the stopwords from NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pd.read_csv(\"data/atis_intents_train.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(\"data/atis_intents_test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['intent','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/atis_intents.csv\",header=None,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what flights are available from pittsburgh to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atis_flight_time</td>\n",
       "      <td>what is the arrival time in san francisco for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>cheapest airfare from tacoma to orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>what is the airfare for flights from denver t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>do you have any flights from denver to baltim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>atis_airline</td>\n",
       "      <td>which airlines fly into and out of denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>does continental fly from boston to san franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>is there a delta flight from denver to san fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4978 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                intent                                               text\n",
       "0          atis_flight   i want to fly from boston at 838 am and arriv...\n",
       "1          atis_flight   what flights are available from pittsburgh to...\n",
       "2     atis_flight_time   what is the arrival time in san francisco for...\n",
       "3         atis_airfare            cheapest airfare from tacoma to orlando\n",
       "4         atis_airfare   round trip fares from pittsburgh to philadelp...\n",
       "...                ...                                                ...\n",
       "4973      atis_airfare   what is the airfare for flights from denver t...\n",
       "4974       atis_flight   do you have any flights from denver to baltim...\n",
       "4975      atis_airline          which airlines fly into and out of denver\n",
       "4976       atis_flight   does continental fly from boston to san franc...\n",
       "4977       atis_flight   is there a delta flight from denver to san fr...\n",
       "\n",
       "[4978 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent                                                   15\n",
       "text      arrival time san francisco 755 flight leaving ...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1058     i'd like a ticket from denver to atlanta with...\n",
       "2297                                   what airline is hp\n",
       "1199     what kind of aircraft does delta fly before 8...\n",
       "3998     are there any flights from new york to montre...\n",
       "309             show me all the flights leaving baltimore\n",
       "2954     again i will repeat i want to make a one way ...\n",
       "1293     first class american flight from philadelphia...\n",
       "2430     show me flights from pittsburgh to san franci...\n",
       "383      show me times for flights from san francisco ...\n",
       "2373     now i'd like to see flights from detroit to s...\n",
       "2027     i'd like information on the least expensive a...\n",
       "2631      what are the flights from pittsburgh to oakland\n",
       "1212     find a flight from san francisco to boston on...\n",
       "2655     now i want to see return flights from miami t...\n",
       "3905             what airlines fly from burbank to denver\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].sample(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4978 entries, 0 to 4977\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   intent  4978 non-null   object\n",
      " 1   text    4978 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 77.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4978, 2)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4978</td>\n",
       "      <td>4978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>22</td>\n",
       "      <td>4634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>what is fare code h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3666</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             intent                  text\n",
       "count          4978                  4978\n",
       "unique           22                  4634\n",
       "top     atis_flight   what is fare code h\n",
       "freq           3666                     8"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent\n",
       "atis_flight                                 3666\n",
       "atis_airfare                                 423\n",
       "atis_ground_service                          255\n",
       "atis_airline                                 157\n",
       "atis_abbreviation                            147\n",
       "atis_aircraft                                 81\n",
       "atis_flight_time                              54\n",
       "atis_quantity                                 51\n",
       "atis_flight#atis_airfare                      21\n",
       "atis_airport                                  20\n",
       "atis_distance                                 20\n",
       "atis_city                                     19\n",
       "atis_ground_fare                              18\n",
       "atis_capacity                                 16\n",
       "atis_flight_no                                12\n",
       "atis_meal                                      6\n",
       "atis_restriction                               6\n",
       "atis_airline#atis_flight_no                    2\n",
       "atis_ground_service#atis_ground_fare           1\n",
       "atis_airfare#atis_flight_time                  1\n",
       "atis_cheapest                                  1\n",
       "atis_aircraft#atis_flight#atis_flight_no       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>atis_abbreviation</td>\n",
       "      <td>what is fare code h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>pittsburgh to denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>flights from boston to pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>atis_airfare</td>\n",
       "      <td>show me the fares from dallas to san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me flights from pittsburgh to philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>newark to cleveland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me flights from denver to philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>atis_ground_service</td>\n",
       "      <td>show me ground transportation in denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>show me the flights from baltimore to oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>i would like to see the flights from denver t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   intent                                               text\n",
       "261     atis_abbreviation                                what is fare code h\n",
       "278           atis_flight                               pittsburgh to denver\n",
       "283           atis_flight                  flights from boston to pittsburgh\n",
       "285          atis_airfare     show me the fares from dallas to san francisco\n",
       "542           atis_flight    show me flights from pittsburgh to philadelphia\n",
       "...                   ...                                                ...\n",
       "4936          atis_flight                                newark to cleveland\n",
       "4939          atis_flight        show me flights from denver to philadelphia\n",
       "4940  atis_ground_service            show me ground transportation in denver\n",
       "4949          atis_flight      show me the flights from baltimore to oakland\n",
       "4956          atis_flight   i would like to see the flights from denver t...\n",
       "\n",
       "[344 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>atis_airport</td>\n",
       "      <td>airports in new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>atis_airport</td>\n",
       "      <td>airports in new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>atis_flight#atis_airfare</td>\n",
       "      <td>all flights and fares from atlanta to dallas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>atis_flight#atis_airfare</td>\n",
       "      <td>all flights and fares from atlanta to dallas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>atis_flight#atis_airfare</td>\n",
       "      <td>all flights and fares from atlanta to dallas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>atis_airline</td>\n",
       "      <td>which airlines have first class flights today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>which flights are between boston and baltimor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>which flights are between boston and baltimor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>which united airlines flights go through denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>atis_flight</td>\n",
       "      <td>which united airlines flights go through denver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        intent  \\\n",
       "3795              atis_airport   \n",
       "2412              atis_airport   \n",
       "2874  atis_flight#atis_airfare   \n",
       "602   atis_flight#atis_airfare   \n",
       "859   atis_flight#atis_airfare   \n",
       "...                        ...   \n",
       "64                atis_airline   \n",
       "4329               atis_flight   \n",
       "1481               atis_flight   \n",
       "2012               atis_flight   \n",
       "3661               atis_flight   \n",
       "\n",
       "                                                   text  \n",
       "3795                               airports in new york  \n",
       "2412                               airports in new york  \n",
       "2874   all flights and fares from atlanta to dallas ...  \n",
       "602    all flights and fares from atlanta to dallas ...  \n",
       "859    all flights and fares from atlanta to dallas ...  \n",
       "...                                                 ...  \n",
       "64        which airlines have first class flights today  \n",
       "4329   which flights are between boston and baltimor...  \n",
       "1481   which flights are between boston and baltimor...  \n",
       "2012    which united airlines flights go through denver  \n",
       "3661    which united airlines flights go through denver  \n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .loc[df.duplicated(keep=False)]\n",
    "    .sort_values(['text'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the Duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23744\\3190746377.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(clean_text)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23744\\3190746377.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['intent'] = label_encoder.fit_transform(df['intent'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>want fly boston 838 arrive denver 1110 morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>flights available pittsburgh baltimore thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>arrival time san francisco 755 flight leaving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cheapest airfare tacoma orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>round trip fares pittsburgh philadelphia 1000 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intent                                               text\n",
       "0      12     want fly boston 838 arrive denver 1110 morning\n",
       "1      12  flights available pittsburgh baltimore thursda...\n",
       "2      15  arrival time san francisco 755 flight leaving ...\n",
       "3       3                    cheapest airfare tacoma orlando\n",
       "4       3  round trip fares pittsburgh philadelphia 1000 ..."
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function for text cleaning\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalnum()]\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['intent'] = label_encoder.fit_transform(df['intent'])\n",
    "\n",
    "\n",
    "label_encoder_filename = 'label_encoder.joblib'\n",
    "joblib.dump(label_encoder, label_encoder_filename)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "intent       \n",
       "12       3426\n",
       "3         403\n",
       "17        235\n",
       "5         148\n",
       "0         108\n",
       "1          78\n",
       "15         52\n",
       "20         49\n",
       "11         20\n",
       "10         18\n",
       "7          18\n",
       "16         17\n",
       "13         17\n",
       "8          16\n",
       "14         12\n",
       "19          6\n",
       "21          5\n",
       "6           2\n",
       "18          1\n",
       "4           1\n",
       "9           1\n",
       "2           1"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df['intent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (4634, 5000)\n",
      "TF-IDF vectorizer saved to tfidf_vectorizer_ngram.joblib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>want fly boston 838 arrive denver 1110 morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>flights available pittsburgh baltimore thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>arrival time san francisco 755 flight leaving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>cheapest airfare tacoma orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>round trip fares pittsburgh philadelphia 1000 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   intent                                               text\n",
       "0      12     want fly boston 838 arrive denver 1110 morning\n",
       "1      12  flights available pittsburgh baltimore thursda...\n",
       "2      15  arrival time san francisco 755 flight leaving ...\n",
       "3       3                    cheapest airfare tacoma orlando\n",
       "4       3  round trip fares pittsburgh philadelphia 1000 ..."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 3))\n",
    "\n",
    "X = tfidf_vector.fit_transform(df['text'])\n",
    "\n",
    "print(f\"TF-IDF matrix shape: {X.shape}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer to a file\n",
    "vectorizer_filename = 'tfidf_vectorizer_ngram.joblib'\n",
    "joblib.dump(tfidf_vector, vectorizer_filename)\n",
    "print(f\"TF-IDF vectorizer saved to {vectorizer_filename}\")\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.8813376483279396,\n",
       "  'Precision': 0.8603983633080451,\n",
       "  'Recall': 0.8813376483279396,\n",
       "  'F1 Score': 0.8534389519874469},\n",
       " 'SVM': {'Accuracy': 0.9277238403451996,\n",
       "  'Precision': 0.9221302387845821,\n",
       "  'Recall': 0.9277238403451996,\n",
       "  'F1 Score': 0.9159594778355201},\n",
       " 'Random Forest': {'Accuracy': 0.9223300970873787,\n",
       "  'Precision': 0.9191844355562371,\n",
       "  'Recall': 0.9223300970873787,\n",
       "  'F1 Score': 0.9133288989694733}}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['intent'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate the models\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    results[model_name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Display the results\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.881338</td>\n",
       "      <td>0.927724</td>\n",
       "      <td>0.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.860398</td>\n",
       "      <td>0.922130</td>\n",
       "      <td>0.919184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.881338</td>\n",
       "      <td>0.927724</td>\n",
       "      <td>0.922330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.853439</td>\n",
       "      <td>0.915959</td>\n",
       "      <td>0.913329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression       SVM  Random Forest\n",
       "Accuracy              0.881338  0.927724       0.922330\n",
       "Precision             0.860398  0.922130       0.919184\n",
       "Recall                0.881338  0.927724       0.922330\n",
       "F1 Score              0.853439  0.915959       0.913329"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 11s 178ms/step - loss: 1.5391 - accuracy: 0.7137 - val_loss: 1.0314 - val_accuracy: 0.7749\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 8s 163ms/step - loss: 1.1677 - accuracy: 0.7288 - val_loss: 1.0467 - val_accuracy: 0.7749\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 8s 166ms/step - loss: 1.1636 - accuracy: 0.7288 - val_loss: 1.0265 - val_accuracy: 0.7749\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 8s 168ms/step - loss: 1.1616 - accuracy: 0.7288 - val_loss: 1.0391 - val_accuracy: 0.7749\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 8s 172ms/step - loss: 1.1615 - accuracy: 0.7288 - val_loss: 1.0258 - val_accuracy: 0.7749\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 8s 167ms/step - loss: 1.1623 - accuracy: 0.7288 - val_loss: 1.0260 - val_accuracy: 0.7749\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 8s 175ms/step - loss: 1.1604 - accuracy: 0.7288 - val_loss: 1.0328 - val_accuracy: 0.7749\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 9s 196ms/step - loss: 1.1637 - accuracy: 0.7288 - val_loss: 1.0258 - val_accuracy: 0.7749\n",
      "29/29 [==============================] - 1s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.7443365695792881,\n",
       " 'Precision': 0.5540369288130623,\n",
       " 'Recall': 0.7443365695792881,\n",
       " 'F1 Score': 0.6352408571548654}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the maximum number of words and the maximum sequence length\n",
    "max_words = 5000\n",
    "max_len = 100\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['text'])\n",
    "\n",
    "# Convert the text to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(df['text'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_seq, X_test_seq, y_train, y_test = train_test_split(padded_sequences, df['intent'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(22, activation='softmax'))  # 22 is the number of unique intents\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with 10 epochs and used early_stopping \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train_seq, y_train, epochs=10, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_seq = model.predict(X_test_seq)\n",
    "y_pred_classes = y_pred_seq.argmax(axis=-1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_classes, average='weighted')\n",
    "\n",
    "# Display the evaluation metrics\n",
    "lstm_results = {\n",
    "    \"Accuracy\": accuracy,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1 Score\": f1\n",
    "}\n",
    "\n",
    "lstm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* The SVM model is the best among the four models including LSTM based on the provided metrics. \n",
    "* It has the highest accuracy, precision, recall, and F1 score, making it the most effective model for intent classification on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Cross-Validation Score: 0.9425410405549431\n",
      "Accuracy: 0.9320388349514563\n",
      "Precision: 0.9311815542677491\n",
      "Recall: 0.9320388349514563\n",
      "F1 Score: 0.9290386721077591\n",
      "Model saved to best_svm_model_ngram.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Initialize Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(svm, param_grid, refit=True, verbose=2, cv=5, n_jobs=-1)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Cross-Validation Score: {best_score}\")\n",
    "\n",
    "# Train the best model on the entire training set\n",
    "best_svm = grid_search.best_estimator_\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best = best_svm.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "best_precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_best, average='weighted')\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(f\"Accuracy: {best_accuracy}\")\n",
    "print(f\"Precision: {best_precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'best_svm_model_ngram.joblib'\n",
    "joblib.dump(best_svm, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obervation after the Hyper parameter Tuning\n",
    "\n",
    "* The SVM model with tuned hyperparameters is performing excellently, with high accuracy, precision, recall, and F1 score. \n",
    "* The slight imbalance in class predictions will be done by SMOTE but which isnt required almost model works well without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from collections import Counter\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# import string\n",
    "\n",
    "# # Load the dataset\n",
    "# file_path = '/mnt/data/atis_intents.csv'\n",
    "# atis_data = pd.read_csv(file_path)\n",
    "\n",
    "# # Rename columns\n",
    "# atis_data.columns = ['intent', 'text']\n",
    "\n",
    "# # Check for missing values\n",
    "# missing_values = atis_data.isnull().sum()\n",
    "# print(f\"Missing values:\\n{missing_values}\")\n",
    "\n",
    "# # Remove duplicate rows\n",
    "# atis_data = atis_data.drop_duplicates()\n",
    "\n",
    "# # Verify removal of duplicates\n",
    "# remaining_duplicates = atis_data.duplicated().sum()\n",
    "# print(f\"Remaining duplicates: {remaining_duplicates}\")\n",
    "\n",
    "# # Download the stopwords from NLTK\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# # Define a function for text cleaning\n",
    "# def clean_text(text):\n",
    "#     # Convert text to lowercase\n",
    "#     text = text.lower()\n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text)\n",
    "#     # Remove punctuation\n",
    "#     tokens = [word for word in tokens if word.isalnum()]\n",
    "#     # Remove stop words\n",
    "#     tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "#     return ' '.join(tokens)\n",
    "\n",
    "# # Apply the text cleaning function to the 'text' column\n",
    "# atis_data['text'] = atis_data['text'].apply(clean_text)\n",
    "\n",
    "# # Encode labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# atis_data['intent'] = label_encoder.fit_transform(atis_data['intent'])\n",
    "\n",
    "# # Initialize the TF-IDF Vectorizer with n-grams (unigrams, bigrams, trigrams)\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 3))\n",
    "\n",
    "# # Fit and transform the text data\n",
    "# X = tfidf_vectorizer.fit_transform(atis_data['text'])\n",
    "\n",
    "# # Save the TF-IDF vectorizer to a file\n",
    "# vectorizer_filename = 'tfidf_vectorizer_ngram.joblib'\n",
    "# joblib.dump(tfidf_vectorizer, vectorizer_filename)\n",
    "# print(f\"TF-IDF vectorizer saved to {vectorizer_filename}\")\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, atis_data['intent'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "\n",
    "# # Apply SMOTE to the training data\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Check the class distribution after resampling\n",
    "# print(f\"Class distribution after SMOTE: {Counter(y_train_resampled)}\")\n",
    "\n",
    "# # Define the parameter grid for Grid Search\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100, 1000],\n",
    "#     'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "\n",
    "# # Initialize the SVM model\n",
    "# svm = SVC(random_state=42)\n",
    "\n",
    "# # Initialize Grid Search with Cross-Validation\n",
    "# grid_search = GridSearchCV(svm, param_grid, refit=True, verbose=2, cv=5, n_jobs=-1)\n",
    "\n",
    "# # Perform Grid Search\n",
    "# grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Get the best parameters and the best score\n",
    "# best_params = grid_search.best_params_\n",
    "# best_score = grid_search.best_score_\n",
    "\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# print(f\"Best Cross-Validation Score: {best_score}\")\n",
    "\n",
    "# # Train the best model on the entire training set\n",
    "# best_svm = grid_search.best_estimator_\n",
    "# best_svm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_best = best_svm.predict(X_test)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "# best_precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred_best, average='weighted', zero_division=1)\n",
    "\n",
    "# # Display the evaluation metrics\n",
    "# print(f\"Accuracy: {best_accuracy}\")\n",
    "# print(f\"Precision: {best_precision}\")\n",
    "# print(f\"Recall: {recall}\")\n",
    "# print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# # Save the model to a file\n",
    "# model_filename = 'best_svm_model_ngram.joblib'\n",
    "# joblib.dump(best_svm, model_filename)\n",
    "# print(f\"Model saved to {model_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvatis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
